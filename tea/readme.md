# ğŸ§  CLEAR: Conceptual Latent Encoding with Attentive Reconstructions

**CLEAR** is a modular, interpretable deep learning architecture designed to learn and explain semantic representations in high-dimensional data.

CLEAR stands for:

> **C**onceptual  
> **L**atent  
> **E**ncoding with  
> **A**ttentive  
> **R**econstructions  

At its core, CLEAR is a **semantic latent autoencoder** â€” a model that doesnâ€™t just compress data, but organizes it into **conceptual units** using self-organizing maps (SOMs), then reconstructs meaningful representations through gated attention.

---

## ğŸ” What Makes CLEAR Unique

- ğŸ§© **Self-Organizing Maps (SOMs)** per node to enforce topological structure on latent prototypes  
- ğŸ” **Attentional gating** to blend concepts in a compositional, interpretable way  
- ğŸŒ± **Modular node growth**, allowing the model to expand as needed  
- ğŸ–¼ï¸ **Explainable reconstructions** from clean targets â€” not pixel supervision, but latent denoising  
- ğŸ“ˆ **Growth-driven training** using entropy, variance, and diversity diagnostics  
- ğŸ§  **Clusterable, visualizable prototype grids** per node for deep explainability  

---

## ğŸ’¡ What It's For

CLEAR is built to bridge the gap between **deep performance** and **deep understanding**:

- Interpretable image classification
- Self-supervised representation learning
- Regression or generation via modular heads (coming soon)
- Prototype-based explanations
- Curriculum learning with growable modules

---

## ğŸ“¸ Example Outputs

- âœ… Node-wise prototype clusters  
- âœ… Blended reconstructions (per node)  
- âœ… Gating dynamics and entropy over time  
- âœ… Visual concept audit trails

---

## ğŸš€ Coming Soon

- Top-k cluster visualizers
- Latent traversal tools
- Interactive dashboards for inspecting node behavior
- Support for regression and generation heads

---

## ğŸ§ª Get Started

```bash
python train_cifar.py
python visualize_cifar.py
