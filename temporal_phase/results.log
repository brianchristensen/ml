8L/128D
================================================================================
Training Single-Layer Novel Attention
================================================================================

Parameters: 2,959,880

Epoch 1/5
  Batch 100/1099 - Loss: 3.2769 - BPC: 4.7276
  Batch 200/1099 - Loss: 2.9654 - BPC: 4.2782
  Batch 300/1099 - Loss: 2.7704 - BPC: 3.9969
  Batch 400/1099 - Loss: 2.6283 - BPC: 3.7918
  Batch 500/1099 - Loss: 2.5234 - BPC: 3.6405
  Batch 600/1099 - Loss: 2.4406 - BPC: 3.5210
  Batch 700/1099 - Loss: 2.3732 - BPC: 3.4238
  Batch 800/1099 - Loss: 2.3176 - BPC: 3.3436
  Batch 900/1099 - Loss: 2.2711 - BPC: 3.2764
  Batch 1000/1099 - Loss: 2.2325 - BPC: 3.2208
Train BPC: 3.1720 - Val BPC: 2.7217

  Saved best model (Val BPC: 2.7217)
Epoch 2/5
  Batch 100/1099 - Loss: 1.8231 - BPC: 2.6302
  Batch 200/1099 - Loss: 1.8086 - BPC: 2.6092
  Batch 300/1099 - Loss: 1.8077 - BPC: 2.6080
  Batch 400/1099 - Loss: 1.7986 - BPC: 2.5948
  Batch 500/1099 - Loss: 1.7938 - BPC: 2.5879
  Batch 600/1099 - Loss: 1.7888 - BPC: 2.5807
  Batch 700/1099 - Loss: 1.7862 - BPC: 2.5769
  Batch 800/1099 - Loss: 1.7801 - BPC: 2.5681
  Batch 900/1099 - Loss: 1.7735 - BPC: 2.5587
  Batch 1000/1099 - Loss: 1.7692 - BPC: 2.5525
Train BPC: 2.5471 - Val BPC: 2.5423

  Saved best model (Val BPC: 2.5423)
Epoch 3/5
  Batch 100/1099 - Loss: 1.7366 - BPC: 2.5053
  Batch 200/1099 - Loss: 1.7320 - BPC: 2.4987
  Batch 300/1099 - Loss: 1.7251 - BPC: 2.4888
  Batch 400/1099 - Loss: 1.7148 - BPC: 2.4740
  Batch 500/1099 - Loss: 1.7074 - BPC: 2.4633
  Batch 600/1099 - Loss: 1.7015 - BPC: 2.4547
  Batch 700/1099 - Loss: 1.6955 - BPC: 2.4462
  Batch 800/1099 - Loss: 1.6906 - BPC: 2.4391
  Batch 900/1099 - Loss: 1.6860 - BPC: 2.4324
  Batch 1000/1099 - Loss: 1.6806 - BPC: 2.4246
Train BPC: 2.4188 - Val BPC: 2.4681

  Saved best model (Val BPC: 2.4681)
Epoch 4/5
  Batch 100/1099 - Loss: 1.6213 - BPC: 2.3390
  Batch 200/1099 - Loss: 1.6227 - BPC: 2.3411
  Batch 300/1099 - Loss: 1.6229 - BPC: 2.3413
  Batch 400/1099 - Loss: 1.6185 - BPC: 2.3351
  Batch 500/1099 - Loss: 1.6251 - BPC: 2.3446
  Batch 600/1099 - Loss: 1.7277 - BPC: 2.4926
  Batch 700/1099 - Loss: 1.7271 - BPC: 2.4916
  Batch 800/1099 - Loss: 1.7172 - BPC: 2.4773
  Batch 900/1099 - Loss: 1.7048 - BPC: 2.4596
  Batch 1000/1099 - Loss: 1.6956 - BPC: 2.4463
Train BPC: 2.4348 - Val BPC: 2.3929

  Saved best model (Val BPC: 2.3929)
Epoch 5/5
  Batch 100/1099 - Loss: 1.5843 - BPC: 2.2856
  Batch 200/1099 - Loss: 1.5940 - BPC: 2.2997
  Batch 300/1099 - Loss: 1.5894 - BPC: 2.2930
  Batch 400/1099 - Loss: 1.5867 - BPC: 2.2891
  Batch 500/1099 - Loss: 1.5843 - BPC: 2.2856
  Batch 600/1099 - Loss: 1.5887 - BPC: 2.2920
  Batch 700/1099 - Loss: 1.5884 - BPC: 2.2915
  Batch 800/1099 - Loss: 1.5889 - BPC: 2.2923
  Batch 900/1099 - Loss: 1.5887 - BPC: 2.2920
  Batch 1000/1099 - Loss: 1.5882 - BPC: 2.2914
Train BPC: 2.3169 - Val BPC: 2.9667

Final Test BPC: 3.0099

Saved final model to tempo_charlm_final.pt

================================================================================
Results Summary
================================================================================

Model                            Parameters   Best Val BPC     Test BPC
--------------------------------------------------------------------------------
Novel Attention                   2,959,880         2.3929       3.0099

Test 1/3: The capital of France is
================================================================================

TRANSFORMER:
--------------------------------------------------------------------------------
Seed: The capital of France is
Generating 150 characters (top-k=40)...

================================================================================
 president current to the about the small the considered on the state, but slaves on and the operation centerious of a that he connections for the tri
================================================================================

PHASE ATTENTION:
--------------------------------------------------------------------------------
Seed: The capital of France is
Generating 150 characters (top-k=40)...

================================================================================
 Prote]] and [[Pacristory|Astaritice]]. He websth seckened haved merelost sovestionably mechil and [[is laving cone]]. [[[doporty|descition]], [[notse
================================================================================


================================================================================
Test 2/3: In the year 1776
================================================================================

TRANSFORMER:
--------------------------------------------------------------------------------
Seed: In the year 1776
Generating 150 characters (top-k=40)...

================================================================================
.

==See also==

In 1965, because ==
* [[United States|struction]]
[[Category:1966
* [[Berlin World Miran American actor]] rather [[George Stather]]
*
================================================================================

PHASE ATTENTION:
--------------------------------------------------------------------------------
Seed: In the year 1776
Generating 150 characters (top-k=40)...

================================================================================
 Alenor Autaras]]} Anotheic the Itries of the tere had meentary.  The [[Mas Aleks]]] is world as necertlyd is knotly. E.T1999]] the preface the [[sema