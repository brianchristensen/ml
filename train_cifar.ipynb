{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617207d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import v2 as T\n",
    "\n",
    "from tea.model import TEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5c46c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e146a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Hyperparameters ===\n",
    "epochs = 20\n",
    "num_nodes_default = 4\n",
    "latent_dim_default = 256\n",
    "# loss coefficients\n",
    "recon_loss_Î» = 1\n",
    "proto_div_Î» = 4\n",
    "node_div_Î» = 4\n",
    "usage_Î» = 0.7\n",
    "label_smoothing = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b959b751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Model ===\n",
    "model = TEA(num_nodes=num_nodes_default, latent_dim=latent_dim_default).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32430cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# === Data ===\n",
    "transform_train = transforms.ToTensor()\n",
    "transform_test = transforms.ToTensor()\n",
    "\n",
    "train_data = datasets.CIFAR10(\n",
    "    \"data\", train=True, download=True, transform=transform_train\n",
    ")\n",
    "train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
    "test_data = datasets.CIFAR10(\n",
    "    \"data\", train=False, download=True, transform=transform_test\n",
    ")\n",
    "test_loader = DataLoader(test_data, batch_size=128)\n",
    "\n",
    "# Intensive augments - better generality of model, harder to invert prototypes with decoder\n",
    "# gpu_train_aug = T.Compose([\n",
    "#     T.RandomCrop(32, padding=4),\n",
    "#     T.RandomHorizontalFlip(),\n",
    "#     T.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
    "#     T.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
    "#     T.ToDtype(torch.float32, scale=True)\n",
    "# ])\n",
    "\n",
    "# Simpler augments - less generality of model, easier to invert prototypes with decoder\n",
    "gpu_train_aug = T.Compose(\n",
    "    [\n",
    "        T.RandomCrop(32, padding=4),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToDtype(torch.float32, scale=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e237a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§  Training TEA Model @ 2025-04-11 22:50:50\n",
      "[TRAIN] Epoch  1 | Accuracy: 0.2505 | Recon: 21.5453 | Proto Similarity: 1.3872 | Node Similarity: 1.4836 | Usage Penalty: 80.4080 | Node0Tmp: 0.6299 | Node1Tmp: 0.6321 | Node2Tmp: 0.6302 | Node3Tmp: 0.6313 | Duration: 565.97s\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 66\u001b[39m\n\u001b[32m     63\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNode\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mTmp: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode.som.temperature.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     64\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDuration: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_duration\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels/model_tea.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ… Saved to models/model_tea.pth\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brianchristensen/ml/.venv/lib/python3.13/site-packages/torch/serialization.py:943\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[39m\n\u001b[32m    940\u001b[39m _check_save_filelike(f)\n\u001b[32m    942\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[32m--> \u001b[39m\u001b[32m943\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[32m    944\u001b[39m         _save(\n\u001b[32m    945\u001b[39m             obj,\n\u001b[32m    946\u001b[39m             opened_zipfile,\n\u001b[32m   (...)\u001b[39m\u001b[32m    949\u001b[39m             _disable_byteorder_record,\n\u001b[32m    950\u001b[39m         )\n\u001b[32m    951\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brianchristensen/ml/.venv/lib/python3.13/site-packages/torch/serialization.py:810\u001b[39m, in \u001b[36m_open_zipfile_writer\u001b[39m\u001b[34m(name_or_buffer)\u001b[39m\n\u001b[32m    808\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    809\u001b[39m     container = _open_zipfile_writer_buffer\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/brianchristensen/ml/.venv/lib/python3.13/site-packages/torch/serialization.py:781\u001b[39m, in \u001b[36m_open_zipfile_writer_file.__init__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    777\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\n\u001b[32m    778\u001b[39m         torch._C.PyTorchFileWriter(\u001b[38;5;28mself\u001b[39m.file_stream, _compute_crc32)\n\u001b[32m    779\u001b[39m     )\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m781\u001b[39m     \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_compute_crc32\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Parent directory models does not exist."
     ]
    }
   ],
   "source": [
    "# === Training ===\n",
    "print(f\"ðŸ§  Training TEA Model @ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "start_time = time.time()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    model.train()\n",
    "    total_loss = total_acc_topo = 0\n",
    "    total_proto_div = total_node_div = total_usage_penalty = total_recon_loss = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        x_aug = gpu_train_aug(x)\n",
    "        logits = model(x_aug)\n",
    "\n",
    "        # Core losses\n",
    "        loss_cls = F.cross_entropy(logits, y, label_smoothing=label_smoothing)\n",
    "        proto_div = model.proto_diversity_loss()\n",
    "        node_div = model.node_diversity_loss()\n",
    "        usage_penalty = model.usage_penalty()\n",
    "\n",
    "        recon_losses = [\n",
    "            F.mse_loss(model.decoders[i](model.nodes[i].last_blended), x)\n",
    "            for i in range(model.num_nodes)\n",
    "        ]\n",
    "        recon_loss = sum(recon_losses) / model.num_nodes\n",
    "\n",
    "        # Total loss\n",
    "        loss = (\n",
    "            loss_cls\n",
    "            + proto_div_Î» * proto_div\n",
    "            + node_div_Î» * node_div\n",
    "            + usage_Î» * usage_penalty\n",
    "            + recon_loss_Î» * recon_loss\n",
    "        )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # scheduler.step()  # Optional if you enable a scheduler\n",
    "\n",
    "        # Logging\n",
    "        with torch.no_grad():\n",
    "            pred_topo = logits.argmax(dim=1)\n",
    "            total_acc_topo += (pred_topo == y).sum().item()\n",
    "            total_loss += loss.item()\n",
    "            total_proto_div += proto_div.item()\n",
    "            total_node_div += node_div.item()\n",
    "            total_usage_penalty += usage_penalty.item()\n",
    "            total_recon_loss += recon_loss.item()\n",
    "            total_samples += y.size(0)\n",
    "\n",
    "    epoch_duration = time.time() - epoch_start_time\n",
    "\n",
    "    # === Epoch summary ===\n",
    "    print(\n",
    "        f\"[TRAIN] Epoch {epoch:2d} | \"\n",
    "        f\"Accuracy: {total_acc_topo / total_samples:.4f} | \"\n",
    "        f\"Recon: {total_recon_loss:.4f} | \"\n",
    "        f\"Proto Similarity: {total_proto_div:.4f} | \"\n",
    "        f\"Node Similarity: {total_node_div:.4f} | \"\n",
    "        f\"Usage Penalty: {total_usage_penalty:.4f}\",\n",
    "        end=\" | \",\n",
    "    )\n",
    "    for i, node in enumerate(model.nodes):\n",
    "        print(f\"Node{i}Tmp: {node.som.temperature.item():.4f}\", end=\" | \")\n",
    "    print(f\"Duration: {epoch_duration:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704076f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved to models/model_tea.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"models/model_tea.pth\")\n",
    "print(\"âœ… Saved to models/model_tea.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af100982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š [TEST] Accuracy: 0.3984\n",
      "ðŸ“Š Total Duration: 11.00m 52s\n"
     ]
    }
   ],
   "source": [
    "# === Evaluation ===\n",
    "model.eval()\n",
    "total_topo_acc = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "\n",
    "        pred_topo = logits.argmax(dim=1)\n",
    "        total_topo_acc += (pred_topo == y).sum().item()\n",
    "        total_samples += y.size(0)\n",
    "\n",
    "total_duraton = time.time() - start_time\n",
    "print(f\"ðŸ“Š [TEST] Accuracy: {total_topo_acc / total_samples:.4f}\")\n",
    "print(f\"ðŸ“Š Total Duration: {int(total_duraton // 60):.2f}m {int(total_duraton % 60)}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
